{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from random import randint\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XORDataset(Dataset):\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = randint(0, 1)\n",
    "        y = randint(0, 1)\n",
    "        return torch.tensor([x, y]), torch.tensor([x ^ y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "y = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xor_train = XORDataset(1000)\n",
    "xor_test = XORDataset(100)\n",
    "train_loader = DataLoader(xor_train, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(xor_test, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = torch.randn(2, 4, requires_grad=True)\n",
    "b1 = torch.randn(4, requires_grad=True)\n",
    "w2 = torch.randn(4, 1, requires_grad=True)\n",
    "b2 = torch.randn(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = x.float() @ w1 + b1\n",
    "a1 = torch.sigmoid(z1)\n",
    "z2 = a1 @ w2 + b2\n",
    "y_pred = torch.sigmoid(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0115, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -torch.mean(y * torch.log(y_pred) + (1 - y) * torch.log(1 - y_pred))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0115, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.binary_cross_entropy(y_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss 0.679673070192337 validation loss 0.6768500113487244 test accuracy 0.75\n",
      "Epoch 1: train loss 0.6801569554805755 validation loss 0.6725856328010559 test accuracy 0.58\n",
      "Epoch 2: train loss 0.6780541615486145 validation loss 0.674308066368103 test accuracy 0.79\n",
      "Epoch 3: train loss 0.6794984564781189 validation loss 0.6772174549102783 test accuracy 0.76\n",
      "Epoch 4: train loss 0.6760360081195831 validation loss 0.6757626867294312 test accuracy 0.49\n",
      "Epoch 5: train loss 0.6775535476207734 validation loss 0.6625968217849731 test accuracy 0.6\n",
      "Epoch 6: train loss 0.6748241431713105 validation loss 0.6745300483703613 test accuracy 0.75\n",
      "Epoch 7: train loss 0.6730584037303925 validation loss 0.6706727051734924 test accuracy 0.52\n",
      "Epoch 8: train loss 0.6709829375743867 validation loss 0.6770709657669067 test accuracy 0.73\n",
      "Epoch 9: train loss 0.6707784655094147 validation loss 0.6698770165443421 test accuracy 0.72\n",
      "Epoch 10: train loss 0.6687397592067719 validation loss 0.6746891975402832 test accuracy 0.44\n",
      "Epoch 11: train loss 0.6678584406375885 validation loss 0.6673597693443298 test accuracy 0.49\n",
      "Epoch 12: train loss 0.6621613726615906 validation loss 0.6564499402046203 test accuracy 0.77\n",
      "Epoch 13: train loss 0.665689377784729 validation loss 0.6539508199691773 test accuracy 0.54\n",
      "Epoch 14: train loss 0.6646978585720063 validation loss 0.6562235713005066 test accuracy 0.77\n",
      "Epoch 15: train loss 0.6559215359687806 validation loss 0.6633999586105347 test accuracy 0.72\n",
      "Epoch 16: train loss 0.6559046173095703 validation loss 0.6614744567871094 test accuracy 0.74\n",
      "Epoch 17: train loss 0.652146723985672 validation loss 0.6523241090774536 test accuracy 0.51\n",
      "Epoch 18: train loss 0.6527215781211853 validation loss 0.6457021570205689 test accuracy 0.79\n",
      "Epoch 19: train loss 0.6483029408454895 validation loss 0.6558529353141784 test accuracy 0.46\n",
      "Epoch 20: train loss 0.6501094431877136 validation loss 0.6411120796203613 test accuracy 0.53\n",
      "Epoch 21: train loss 0.6421118178367615 validation loss 0.6425976967811584 test accuracy 0.5\n",
      "Epoch 22: train loss 0.640402313709259 validation loss 0.632481369972229 test accuracy 0.55\n",
      "Epoch 23: train loss 0.6447672533988953 validation loss 0.6415109992027282 test accuracy 0.47\n",
      "Epoch 24: train loss 0.6389321057796479 validation loss 0.6393907856941223 test accuracy 0.47\n",
      "Epoch 25: train loss 0.6337266104221344 validation loss 0.6350471878051758 test accuracy 0.48\n",
      "Epoch 26: train loss 0.6260992908477783 validation loss 0.6268476986885071 test accuracy 0.49\n",
      "Epoch 27: train loss 0.6253020977973938 validation loss 0.6297832155227661 test accuracy 0.44\n",
      "Epoch 28: train loss 0.623461359500885 validation loss 0.613454430103302 test accuracy 0.75\n",
      "Epoch 29: train loss 0.6118168483972549 validation loss 0.625074725151062 test accuracy 0.63\n",
      "Epoch 30: train loss 0.612996831536293 validation loss 0.6126828098297119 test accuracy 0.48\n",
      "Epoch 31: train loss 0.6063384076356888 validation loss 0.6131594514846802 test accuracy 0.46\n",
      "Epoch 32: train loss 0.595413067817688 validation loss 0.587929790019989 test accuracy 0.78\n",
      "Epoch 33: train loss 0.604870617389679 validation loss 0.6048462319374085 test accuracy 0.75\n",
      "Epoch 34: train loss 0.5945797927379608 validation loss 0.5835627102851868 test accuracy 0.81\n",
      "Epoch 35: train loss 0.586306097984314 validation loss 0.5823544812202454 test accuracy 0.5\n",
      "Epoch 36: train loss 0.5808870040178299 validation loss 0.59159632563591 test accuracy 0.74\n",
      "Epoch 37: train loss 0.5806476391553879 validation loss 0.5852020001411438 test accuracy 0.74\n",
      "Epoch 38: train loss 0.5625393326282502 validation loss 0.5640693581104279 test accuracy 0.7\n",
      "Epoch 39: train loss 0.562149806857109 validation loss 0.5758896231651306 test accuracy 0.78\n",
      "Epoch 40: train loss 0.5528016589879989 validation loss 0.554356359243393 test accuracy 1.0\n",
      "Epoch 41: train loss 0.5467744462490082 validation loss 0.5566461110115051 test accuracy 1.0\n",
      "Epoch 42: train loss 0.5375306375026703 validation loss 0.5382611298561096 test accuracy 1.0\n",
      "Epoch 43: train loss 0.5318086824417114 validation loss 0.5174138879776001 test accuracy 0.83\n",
      "Epoch 44: train loss 0.53439584171772 validation loss 0.5190391945838928 test accuracy 1.0\n",
      "Epoch 45: train loss 0.5152348053455352 validation loss 0.5148826503753662 test accuracy 0.72\n",
      "Epoch 46: train loss 0.5094505500793457 validation loss 0.5154593431949616 test accuracy 1.0\n",
      "Epoch 47: train loss 0.4989957768917084 validation loss 0.5190350782871246 test accuracy 1.0\n",
      "Epoch 48: train loss 0.48836175656318664 validation loss 0.4771057593822479 test accuracy 1.0\n",
      "Epoch 49: train loss 0.48622164225578307 validation loss 0.49043958067893983 test accuracy 1.0\n",
      "Epoch 50: train loss 0.4740671141147614 validation loss 0.45951693296432494 test accuracy 1.0\n",
      "Epoch 51: train loss 0.45853693795204165 validation loss 0.4559929120540619 test accuracy 1.0\n",
      "Epoch 52: train loss 0.4474477002620697 validation loss 0.4296032345294952 test accuracy 1.0\n",
      "Epoch 53: train loss 0.44341026949882506 validation loss 0.4368423235416412 test accuracy 1.0\n",
      "Epoch 54: train loss 0.43224765014648436 validation loss 0.41806761026382444 test accuracy 1.0\n",
      "Epoch 55: train loss 0.4198950626850128 validation loss 0.4306479477882385 test accuracy 1.0\n",
      "Epoch 56: train loss 0.4102134282588959 validation loss 0.41586279034614565 test accuracy 1.0\n",
      "Epoch 57: train loss 0.4003718605041504 validation loss 0.39144346714019773 test accuracy 1.0\n",
      "Epoch 58: train loss 0.38900979697704313 validation loss 0.3690292239189148 test accuracy 1.0\n",
      "Epoch 59: train loss 0.3738014634847641 validation loss 0.37371580123901366 test accuracy 1.0\n",
      "Epoch 60: train loss 0.371672904253006 validation loss 0.36323422610759737 test accuracy 1.0\n",
      "Epoch 61: train loss 0.36380948913097383 validation loss 0.37083642959594726 test accuracy 1.0\n",
      "Epoch 62: train loss 0.35350984054803847 validation loss 0.3346272325515747 test accuracy 1.0\n",
      "Epoch 63: train loss 0.3371356001496315 validation loss 0.3311434882879257 test accuracy 1.0\n",
      "Epoch 64: train loss 0.3293443239331245 validation loss 0.3226106381416321 test accuracy 1.0\n",
      "Epoch 65: train loss 0.3158667105436325 validation loss 0.3167994022369385 test accuracy 1.0\n",
      "Epoch 66: train loss 0.31178350788354875 validation loss 0.31151878893375395 test accuracy 1.0\n",
      "Epoch 67: train loss 0.30012655079364775 validation loss 0.2974294406175613 test accuracy 1.0\n",
      "Epoch 68: train loss 0.29464687955379487 validation loss 0.28973294973373415 test accuracy 1.0\n",
      "Epoch 69: train loss 0.2790356318950653 validation loss 0.28490992248058317 test accuracy 1.0\n",
      "Epoch 70: train loss 0.26963900625705717 validation loss 0.27701483607292177 test accuracy 1.0\n",
      "Epoch 71: train loss 0.2607099116444588 validation loss 0.2664161109924316 test accuracy 1.0\n",
      "Epoch 72: train loss 0.25808080077171325 validation loss 0.24275489449501036 test accuracy 1.0\n",
      "Epoch 73: train loss 0.24480758237838746 validation loss 0.2382707417011261 test accuracy 1.0\n",
      "Epoch 74: train loss 0.23673432141542436 validation loss 0.24265726506710053 test accuracy 1.0\n",
      "Epoch 75: train loss 0.23084426391124727 validation loss 0.22459657669067382 test accuracy 1.0\n",
      "Epoch 76: train loss 0.22580275106430053 validation loss 0.22977363348007201 test accuracy 1.0\n",
      "Epoch 77: train loss 0.21791167098283767 validation loss 0.21639903128147125 test accuracy 1.0\n",
      "Epoch 78: train loss 0.21028786081075668 validation loss 0.21486925542354585 test accuracy 1.0\n",
      "Epoch 79: train loss 0.20201171910762786 validation loss 0.20277723729610442 test accuracy 1.0\n",
      "Epoch 80: train loss 0.2010624651312828 validation loss 0.1921740037202835 test accuracy 1.0\n",
      "Epoch 81: train loss 0.19078424769639968 validation loss 0.18646239519119262 test accuracy 1.0\n",
      "Epoch 82: train loss 0.18974249649047853 validation loss 0.18446386694908143 test accuracy 1.0\n",
      "Epoch 83: train loss 0.17621625497937202 validation loss 0.18051351487636566 test accuracy 1.0\n",
      "Epoch 84: train loss 0.17559576964378357 validation loss 0.16699349105358124 test accuracy 1.0\n",
      "Epoch 85: train loss 0.17591904711723327 validation loss 0.17530327796936035 test accuracy 1.0\n",
      "Epoch 86: train loss 0.16780586457252503 validation loss 0.16147517144680024 test accuracy 1.0\n",
      "Epoch 87: train loss 0.16433894470334054 validation loss 0.1669325539469719 test accuracy 1.0\n",
      "Epoch 88: train loss 0.15784380137920379 validation loss 0.15947461664676665 test accuracy 1.0\n",
      "Epoch 89: train loss 0.15170294725894928 validation loss 0.15325435042381286 test accuracy 1.0\n",
      "Epoch 90: train loss 0.14917788657546044 validation loss 0.14645871371030808 test accuracy 1.0\n",
      "Epoch 91: train loss 0.14611311417818068 validation loss 0.14226646602153778 test accuracy 1.0\n",
      "Epoch 92: train loss 0.14230852302908897 validation loss 0.1387821102142334 test accuracy 1.0\n",
      "Epoch 93: train loss 0.14036365565657616 validation loss 0.13582425117492675 test accuracy 1.0\n",
      "Epoch 94: train loss 0.13450226703286172 validation loss 0.13022641718387604 test accuracy 1.0\n",
      "Epoch 95: train loss 0.1322818079292774 validation loss 0.12991170525550844 test accuracy 1.0\n",
      "Epoch 96: train loss 0.12888060462474824 validation loss 0.12600853323936462 test accuracy 1.0\n",
      "Epoch 97: train loss 0.12684217390418054 validation loss 0.11987447112798691 test accuracy 1.0\n",
      "Epoch 98: train loss 0.12308813971281052 validation loss 0.12371008038520813 test accuracy 1.0\n",
      "Epoch 99: train loss 0.120018972158432 validation loss 0.11834000140428542 test accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    total_train_loss = 0\n",
    "    total_validation_loss = 0\n",
    "    test_accuracy = 0\n",
    "    for i, (x, y) in enumerate(train_loader):    \n",
    "        z1 = x.float() @ w1 + b1\n",
    "        a1 = torch.sigmoid(z1)\n",
    "        z2 = a1 @ w2 + b2\n",
    "        y_pred = torch.sigmoid(z2)\n",
    "\n",
    "        w1.grad = None\n",
    "        b1.grad = None\n",
    "        w2.grad = None\n",
    "        b2.grad = None\n",
    "\n",
    "        loss = loss = -torch.mean(y * torch.log(y_pred) + (1 - y) * torch.log(1 - y_pred))\n",
    "        loss.backward()\n",
    "        total_train_loss += loss.item()\n",
    "        with torch.no_grad():\n",
    "            w1 -= 0.01 * w1.grad\n",
    "            b1 -= 0.01 * b1.grad\n",
    "            w2 -= 0.01 * w2.grad\n",
    "            b2 -= 0.01 * b2.grad\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(test_loader):\n",
    "            z1 = x.float() @ w1 + b1\n",
    "            a1 = torch.sigmoid(z1)\n",
    "            z2 = a1 @ w2 + b2\n",
    "            y_pred = torch.sigmoid(z2)\n",
    "            loss = -torch.mean(y * torch.log(y_pred) + (1 - y) * torch.log(1 - y_pred))\n",
    "            total_validation_loss += loss.item()\n",
    "            accuracy = ((y_pred > 0.5) == y).sum().item() / y.shape[0]\n",
    "            test_accuracy += accuracy\n",
    "    print(f\"Epoch {epoch}: train loss {total_train_loss / len(train_loader)} validation loss {total_validation_loss / len(test_loader)} test accuracy {test_accuracy / len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "y = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)\n",
    "\n",
    "z1 = x.float() @ w1 + b1\n",
    "a1 = torch.sigmoid(z1)\n",
    "z2 = a1 @ w2 + b2\n",
    "y_pred = torch.sigmoid(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred > 0.5 ).int()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
